{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d24a427c-9452-45e2-a7bf-90e00e8ef9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-17 11:53:10.242579: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-17 11:53:13.311608: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "656e196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be7a495a-9e0d-42a1-8594-342786e5af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),           \n",
    "    transforms.Normalize(            \n",
    "        mean=[0.485, 0.456, 0.406],  \n",
    "        std=[0.229, 0.224, 0.225]   \n",
    "    )\n",
    "])\n",
    "\n",
    "train_data = datasets.Imagenette(root='data', split='train', download=False, transform=transform)\n",
    "test_data = datasets.Imagenette(root='data', split='val', download=False, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e2c2ebc-0017-4892-85f7-53b6a1eb8f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tench', 'Tinca tinca'),\n",
       " ('English springer', 'English springer spaniel'),\n",
       " ('cassette player',),\n",
       " ('chain saw', 'chainsaw'),\n",
       " ('church', 'church building'),\n",
       " ('French horn', 'horn'),\n",
       " ('garbage truck', 'dustcart'),\n",
       " ('gas pump', 'gasoline pump', 'petrol pump', 'island dispenser'),\n",
       " ('golf ball',),\n",
       " ('parachute', 'chute')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdb6cce2-e4e5-4aaa-8386-3b61cf89e13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG11(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(VGG11, self).__init__()\n",
    "        self.conv3_1 = nn.Conv2d(3, 64, (3,3), stride=1, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(64, 128, (3,3), stride=1, padding=1)\n",
    "        self.conv3_3 = nn.Conv2d(128, 256, (3,3), stride=1, padding=1)\n",
    "        self.conv3_4 = nn.Conv2d(256, 256, (3,3), stride=1, padding=1)\n",
    "        self.conv3_5 = nn.Conv2d(256, 512, (3,3), stride=1, padding=1)\n",
    "        self.conv3_6 = nn.Conv2d(512, 512, (3,3), stride=1, padding=1)\n",
    "        self.conv3_7 = nn.Conv2d(512, 512, (3,3), stride=1, padding=1)\n",
    "        self.conv3_8 = nn.Conv2d(512, 512, (3,3), stride=1, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(7*7*512, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, len(train_data.classes))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = F.relu(self.conv3_1(X))\n",
    "        out = F.max_pool2d(out, (2,2), stride=2) # 112\n",
    "        out = F.relu(self.conv3_2(out))          # <-- Use 'out' as input\n",
    "        out = F.max_pool2d(out, (2,2), stride=2) # 56\n",
    "        out = F.relu(self.conv3_3(out))          # <-- Use 'out' as input\n",
    "        out = F.relu(self.conv3_4(out))\n",
    "        out = F.max_pool2d(out, (2,2), stride=2) # 28\n",
    "        out = F.relu(self.conv3_5(out))          # <-- Use 'out' as input\n",
    "        out = F.relu(self.conv3_6(out))\n",
    "        out = F.max_pool2d(out, (2,2), stride=2) # 14\n",
    "        out = F.relu(self.conv3_7(out))          # <-- Use 'out' as input\n",
    "        out = F.relu(self.conv3_8(out))\n",
    "        out = F.max_pool2d(out, (2,2), stride=2) # 7\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.dropout2d(out, 0.5)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "946a6648-7d8f-4f67-b9a3-e8250399a907",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f2d019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG11().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5a91740",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2a4bc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(test_data, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6d476a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] train loss: 2.304\n",
      "[1,   200] train loss: 2.305\n",
      "[1,   300] train loss: 2.304\n",
      "[1,   400] train loss: 2.304\n",
      "[1,   500] train loss: 2.305\n",
      "[1] val loss: 2.304, train accuracy: 0.092, val accuracy: 0.099\n",
      "[2,   100] train loss: 2.304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        total_correct += (torch.max(outputs, 1)[1] == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "        if i % 100 == 99:    # Print every 100 mini-batches\n",
    "            print('[%d, %5d] train loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "            # Log the running loss to TensorBoard\n",
    "            writer.add_scalar('training loss', running_loss / 100, epoch * len(train_loader) + i)\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Calculate training accuracy\n",
    "    train_accuracy = total_correct / total_samples\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            total_correct += (torch.max(outputs, 1)[1] == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    # Calculate validation loss and accuracy\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = total_correct / total_samples\n",
    "\n",
    "    print('[%d] val loss: %.3f, train accuracy: %.3f, val accuracy: %.3f' % (epoch + 1, val_loss, train_accuracy, val_accuracy))\n",
    "    # Log validation loss and accuracy to TensorBoard\n",
    "    writer.add_scalar('validation loss', val_loss, epoch)\n",
    "    writer.add_scalar('training accuracy', train_accuracy, epoch)\n",
    "    writer.add_scalar('validation accuracy', val_accuracy, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afee2daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f3c089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271fae14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e26df8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d6465d-dc39-4d30-8702-7968d10020f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
